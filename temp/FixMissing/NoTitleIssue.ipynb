{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-27T13:02:53.052342Z",
     "start_time": "2025-03-27T13:02:52.899581Z"
    }
   },
   "source": "import pandas as pd",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "original_Lux = pd.read_json('Luxury_Beauty.json', lines=True)\n",
    "original_meta = pd.read_json('meta_Luxury_Beauty.json', lines=True)\n",
    "prime = pd.read_json('meta_Prime_Pantry.json', lines=True)\n",
    "\n",
    "df = original_Lux.copy()\n",
    "meta = original_meta[['title', 'description', 'asin']].copy()\n"
   ],
   "id": "5b714e4a782d51a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "test = pd.read_json('test_meta_Luxury_Beauty.json', lines=True)\n",
    "with open('Luxury_Beauty_text_name_dict.json', 'rb') as f:\n",
    "    name_dict = pickle.load(f)\n",
    "df = pd.DataFrame(name_dict)"
   ],
   "id": "4202d5181ec353b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open('Luxury_Beauty_draft_69.json', 'rb') as f:\n",
    "    temp = pickle.load(f)\n",
    "df2 = pd.DataFrame(temp)"
   ],
   "id": "133f124357111dff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import os.path\n",
    "import gzip\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in tqdm(g):\n",
    "        yield json.loads(l)\n",
    "\n",
    "\n",
    "def preprocess(fname):\n",
    "    countU = defaultdict(lambda: 0)\n",
    "    countP = defaultdict(lambda: 0)\n",
    "    line = 0\n",
    "\n",
    "    file_path = f'{fname}.json.gz'  # review data file\n",
    "\n",
    "    # Counting interactions for each user and item\n",
    "    for l in parse(file_path):\n",
    "        line += 1\n",
    "        asin = l['asin']\n",
    "        rev = l['reviewerID']\n",
    "        time = l['unixReviewTime']\n",
    "        countU[rev] += 1\n",
    "        countP[asin] += 1\n",
    "\n",
    "    usermap = dict()\n",
    "    usernum = 0\n",
    "    itemmap = dict()  # maps ASIN to an initial (possibly non-sequential) ID\n",
    "    itemnum = 0\n",
    "    User = dict()\n",
    "    review_dict = {}\n",
    "    name_dict = {'title': {}, 'description': {}}\n",
    "\n",
    "    # Load raw meta data\n",
    "    with open(f'meta_{fname}.json', 'r') as f:\n",
    "        json_data = f.readlines()\n",
    "    data_list = [json.loads(line.strip()) for line in json_data]\n",
    "    meta_dict = {}\n",
    "    for l in data_list:\n",
    "        meta_dict[l['asin']] = l\n",
    "\n",
    "    # Process the review data\n",
    "    for l in parse(file_path):\n",
    "        line += 1\n",
    "        asin = l['asin']\n",
    "        rev = l['reviewerID']\n",
    "        time = l['unixReviewTime']\n",
    "\n",
    "        # Set threshold for filtering interactions\n",
    "        threshold = 5\n",
    "        if ('Beauty' in fname) or ('Toys' in fname) or ('Magazine_Subscriptions' in fname):\n",
    "            threshold = 3\n",
    "\n",
    "        if countU[rev] < threshold or countP[asin] < threshold:\n",
    "            continue\n",
    "\n",
    "        # Map reviewer to a new integer ID\n",
    "        if rev in usermap:\n",
    "            userid = usermap[rev]\n",
    "        else:\n",
    "            usernum += 1\n",
    "            userid = usernum\n",
    "            usermap[rev] = userid\n",
    "            User[userid] = []\n",
    "\n",
    "        # Map product ASIN to an initial item ID\n",
    "        if asin in itemmap:\n",
    "            itemid = itemmap[asin]\n",
    "        else:\n",
    "            itemnum += 1\n",
    "            itemid = itemnum\n",
    "            itemmap[asin] = itemid\n",
    "        User[userid].append([time, itemid])\n",
    "\n",
    "        # Build review_dict (optional) and name_dict with meta data\n",
    "        if itemmap[asin] in review_dict:\n",
    "            try:\n",
    "                review_dict[itemmap[asin]]['review'][usermap[rev]] = l['reviewText']\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            try:\n",
    "                review_dict[itemmap[asin]]['summary'][usermap[rev]] = l['summary']\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        else:\n",
    "            review_dict[itemmap[asin]] = {'review': {}, 'summary': {}}\n",
    "            try:\n",
    "                review_dict[itemmap[asin]]['review'][usermap[rev]] = l['reviewText']\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            try:\n",
    "                review_dict[itemmap[asin]]['summary'][usermap[rev]] = l['summary']\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        try:\n",
    "            if len(meta_dict[asin]['description']) == 0:\n",
    "                name_dict['description'][itemmap[asin]] = 'Empty description'\n",
    "            else:\n",
    "                name_dict['description'][itemmap[asin]] = meta_dict[asin]['description'][0]\n",
    "            name_dict['title'][itemmap[asin]] = meta_dict[asin]['title']\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    # --- Re-indexing step ---\n",
    "    # Create new dictionaries with sequential keys and a mapping from old to new IDs.\n",
    "    new_title = {}\n",
    "    new_description = {}\n",
    "    new_itemmap = {}  # maps old item id to new sequential id\n",
    "    new_index = 1\n",
    "    # Sort keys for reproducibility; alternatively, you could iterate in any order.\n",
    "    for old_key in sorted(name_dict['title'].keys()):\n",
    "        new_itemmap[old_key] = new_index\n",
    "        new_title[new_index] = name_dict['title'][old_key]\n",
    "        new_description[new_index] = name_dict['description'][old_key]\n",
    "        new_index += 1\n",
    "    # Replace name_dict with re-indexed dictionaries\n",
    "    name_dict['title'] = new_title\n",
    "    name_dict['description'] = new_description\n",
    "    # Update the total number of items to reflect the new indexing\n",
    "    new_itemnum = len(new_title)\n",
    "\n",
    "    # Update the User interactions: remap item IDs using new_itemmap.\n",
    "    for userid in User.keys():\n",
    "        for i in range(len(User[userid])):\n",
    "            old_itemid = User[userid][i][1]\n",
    "            if old_itemid in new_itemmap:\n",
    "                User[userid][i][1] = new_itemmap[old_itemid]\n",
    "\n",
    "    # Save the re-indexed meta data file\n",
    "    with open(f'{fname}spidey.json.gz', 'wb') as tf:\n",
    "        pickle.dump(name_dict, tf)\n",
    "\n",
    "    for userid in User.keys():\n",
    "        User[userid].sort(key=lambda x: x[0])\n",
    "\n",
    "    print(\"User count:\", usernum, \"Original item count:\", itemnum, \"Re-indexed item count:\", new_itemnum)\n",
    "\n",
    "    # Write user-item interaction pairs using the new indexing\n",
    "    with open(f'{fname}.txt', 'w') as f:\n",
    "        for user in User.keys():\n",
    "            for i in User[user]:\n",
    "                f.write('%d %d\\n' % (user, i[1]))\n"
   ],
   "id": "1183e95483e70c7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "preprocess('Luxury_Beauty')",
   "id": "c51690239c778ca2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df2.info()",
   "id": "88ef443143789d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import os.path\n",
    "import gzip\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in tqdm(g):\n",
    "        yield json.loads(l)\n",
    "\n",
    "\n",
    "def preprocess(fname):\n",
    "    countU = defaultdict(lambda: 0)\n",
    "    countP = defaultdict(lambda: 0)\n",
    "    line = 0\n",
    "\n",
    "    file_path = f'../../data/amazon/{fname}.json.gz'  # review data file\n",
    "\n",
    "    # Counting interactions for each user and item\n",
    "    for l in parse(file_path):\n",
    "        line += 1\n",
    "        asin = l['asin']\n",
    "        rev = l['reviewerID']\n",
    "        time = l['unixReviewTime']\n",
    "        countU[rev] += 1\n",
    "        countP[asin] += 1\n",
    "\n",
    "    usermap = dict()\n",
    "    usernum = 0\n",
    "    itemmap = dict()  # maps ASIN to an initial (possibly non-sequential) ID\n",
    "    itemnum = 0\n",
    "    User = dict()\n",
    "    review_dict = {}\n",
    "    name_dict = {'title': {}, 'description': {}}\n",
    "\n",
    "    # Load raw meta data\n",
    "    with open(f'meta_{fname}.json', 'r') as f:\n",
    "        json_data = f.readlines()\n",
    "    data_list = [json.loads(line.strip()) for line in json_data]\n",
    "    meta_dict = {}\n",
    "    for l in data_list:\n",
    "        meta_dict[l['asin']] = l\n",
    "\n",
    "    # Process the review data\n",
    "    for l in parse(file_path):\n",
    "        line += 1\n",
    "        asin = l['asin']\n",
    "        rev = l['reviewerID']\n",
    "        time = l['unixReviewTime']\n",
    "\n",
    "        # Set threshold for filtering interactions\n",
    "        threshold = 5\n",
    "        if ('Beauty' in fname) or ('Toys' in fname) or ('Magazine_Subscriptions' in fname):\n",
    "            threshold = 3\n",
    "\n",
    "        if countU[rev] < threshold or countP[asin] < threshold:\n",
    "            continue\n",
    "\n",
    "        # Map reviewer to a new integer ID\n",
    "        if rev in usermap:\n",
    "            userid = usermap[rev]\n",
    "        else:\n",
    "            usernum += 1\n",
    "            userid = usernum\n",
    "            usermap[rev] = userid\n",
    "            User[userid] = []\n",
    "\n",
    "        # Map product ASIN to an initial item ID\n",
    "        if asin in itemmap:\n",
    "            itemid = itemmap[asin]\n",
    "        else:\n",
    "            itemnum += 1\n",
    "            itemid = itemnum\n",
    "            itemmap[asin] = itemid\n",
    "        User[userid].append([time, itemid])\n",
    "\n",
    "        # Build review_dict (optional) and name_dict with meta data\n",
    "        if itemmap[asin] in review_dict:\n",
    "            try:\n",
    "                review_dict[itemmap[asin]]['review'][usermap[rev]] = l['reviewText']\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            try:\n",
    "                review_dict[itemmap[asin]]['summary'][usermap[rev]] = l['summary']\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        else:\n",
    "            review_dict[itemmap[asin]] = {'review': {}, 'summary': {}}\n",
    "            try:\n",
    "                review_dict[itemmap[asin]]['review'][usermap[rev]] = l['reviewText']\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            try:\n",
    "                review_dict[itemmap[asin]]['summary'][usermap[rev]] = l['summary']\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        try:\n",
    "            if len(meta_dict[asin]['description']) == 0:\n",
    "                name_dict['description'][itemmap[asin]] = 'Empty description'\n",
    "            else:\n",
    "                name_dict['description'][itemmap[asin]] = meta_dict[asin]['description'][0]\n",
    "            name_dict['title'][itemmap[asin]] = meta_dict[asin]['title']\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    # --- Re-indexing step ---\n",
    "    # Create new dictionaries with sequential keys and a mapping from old to new IDs.\n",
    "    new_title = {}\n",
    "    new_description = {}\n",
    "    new_itemmap = {}  # maps old item id to new sequential id\n",
    "    new_index = 1\n",
    "    # Sort keys for reproducibility; alternatively, you could iterate in any order.\n",
    "    for old_key in sorted(name_dict['title'].keys()):\n",
    "        new_itemmap[old_key] = new_index\n",
    "        new_title[new_index] = name_dict['title'][old_key]\n",
    "        new_description[new_index] = name_dict['description'][old_key]\n",
    "        new_index += 1\n",
    "    # Replace name_dict with re-indexed dictionaries\n",
    "    name_dict['title'] = new_title\n",
    "    name_dict['description'] = new_description\n",
    "    # Update the total number of items to reflect the new indexing\n",
    "    new_itemnum = len(new_title)\n",
    "\n",
    "    # Update the User interactions: remap item IDs using new_itemmap.\n",
    "    for userid in User.keys():\n",
    "        for i in range(len(User[userid])):\n",
    "            old_itemid = User[userid][i][1]\n",
    "            if old_itemid in new_itemmap:\n",
    "                User[userid][i][1] = new_itemmap[old_itemid]\n",
    "\n",
    "    # Save the re-indexed meta data file\n",
    "    with open(f'../../data/amazon/{fname}_text_name_dict.json.gz', 'wb') as tf:\n",
    "        pickle.dump(name_dict, tf)\n",
    "\n",
    "    for userid in User.keys():\n",
    "        User[userid].sort(key=lambda x: x[0])\n",
    "\n",
    "    print(\"User count:\", usernum, \"Original item count:\", itemnum, \"Re-indexed item count:\", new_itemnum)\n",
    "\n",
    "    # Write user-item interaction pairs using the new indexing\n",
    "    with open(f'../../data/amazon/{fname}.txt', 'w') as f:\n",
    "        for user in User.keys():\n",
    "            for i in User[user]:\n",
    "                f.write('%d %d\\n' % (user, i[1]))\n"
   ],
   "id": "2904f67667e56c60"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "preprocess('Luxury_Beauty')",
   "id": "bc79f85fb4b8868"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import os.path\n",
    "import gzip\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in tqdm(g):\n",
    "        yield json.loads(l)\n",
    "\n",
    "def preprocess(fname):\n",
    "    countU = defaultdict(lambda: 0)\n",
    "    countP = defaultdict(lambda: 0)\n",
    "    line = 0\n",
    "\n",
    "    # Build the absolute file path for the review data file.\n",
    "    file_path = os.path.join('..', '..', 'data', 'amazon', f'{fname}.json.gz')\n",
    "\n",
    "    # Counting interactions for each user and item\n",
    "    for l in parse(file_path):\n",
    "        line += 1\n",
    "        asin = l['asin']\n",
    "        rev = l['reviewerID']\n",
    "        time = l['unixReviewTime']\n",
    "        countU[rev] += 1\n",
    "        countP[asin] += 1\n",
    "\n",
    "    usermap = {}\n",
    "    usernum = 0\n",
    "    itemmap = {}  # maps ASIN to an initial (possibly non-sequential) ID\n",
    "    itemnum = 0\n",
    "    User = {}\n",
    "    review_dict = {}\n",
    "    name_dict = {'title': {}, 'description': {}}\n",
    "\n",
    "    # Use an absolute path for the meta file to ensure consistency across runs.\n",
    "    current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    meta_file_path = os.path.join(current_dir, f'meta_{fname}.json')\n",
    "    with open(meta_file_path, 'r') as f:\n",
    "        json_data = f.readlines()\n",
    "    data_list = [json.loads(line.strip()) for line in json_data]\n",
    "    meta_dict = {}\n",
    "    for entry in data_list:\n",
    "        meta_dict[entry['asin']] = entry\n",
    "\n",
    "    print(f\"Loaded meta_dict with {len(meta_dict)} entries for dataset {fname}\")\n",
    "\n",
    "    # Process the review data and build mappings.\n",
    "    for l in parse(file_path):\n",
    "        line += 1\n",
    "        asin = l['asin']\n",
    "        rev = l['reviewerID']\n",
    "        time = l['unixReviewTime']\n",
    "\n",
    "        # Set threshold for filtering interactions.\n",
    "        threshold = 5\n",
    "        if ('Beauty' in fname) or ('Toys' in fname) or ('Magazine_Subscriptions' in fname):\n",
    "            threshold = 3\n",
    "\n",
    "        if countU[rev] < threshold or countP[asin] < threshold:\n",
    "            continue\n",
    "\n",
    "        # Map reviewer to a new integer ID.\n",
    "        if rev in usermap:\n",
    "            userid = usermap[rev]\n",
    "        else:\n",
    "            usernum += 1\n",
    "            userid = usernum\n",
    "            usermap[rev] = userid\n",
    "            User[userid] = []\n",
    "\n",
    "        # Map product ASIN to an initial item ID.\n",
    "        if asin in itemmap:\n",
    "            itemid = itemmap[asin]\n",
    "        else:\n",
    "            itemnum += 1\n",
    "            itemid = itemnum\n",
    "            itemmap[asin] = itemid\n",
    "        User[userid].append([time, itemid])\n",
    "\n",
    "        # Build review_dict (optional) and name_dict with meta data.\n",
    "        if itemmap[asin] in review_dict:\n",
    "            try:\n",
    "                review_dict[itemmap[asin]]['review'][usermap[rev]] = l['reviewText']\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            try:\n",
    "                review_dict[itemmap[asin]]['summary'][usermap[rev]] = l['summary']\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        else:\n",
    "            review_dict[itemmap[asin]] = {'review': {}, 'summary': {}}\n",
    "            try:\n",
    "                review_dict[itemmap[asin]]['review'][usermap[rev]] = l['reviewText']\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            try:\n",
    "                review_dict[itemmap[asin]]['summary'][usermap[rev]] = l['summary']\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "        # Try to assign meta data. If not found, print a warning.\n",
    "        try:\n",
    "            if asin not in meta_dict:\n",
    "                raise KeyError(\"Meta data not found\")\n",
    "            if len(meta_dict[asin]['description']) == 0:\n",
    "                name_dict['description'][itemmap[asin]] = 'Empty description'\n",
    "            else:\n",
    "                name_dict['description'][itemmap[asin]] = meta_dict[asin]['description'][0]\n",
    "            name_dict['title'][itemmap[asin]] = meta_dict[asin]['title']\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Missing or invalid meta data for ASIN {asin}: {e}\")\n",
    "\n",
    "    print(f\"Number of items with meta data before re-indexing: {len(name_dict['title'])}\")\n",
    "\n",
    "    # --- Re-indexing step ---\n",
    "    new_title = {}\n",
    "    new_description = {}\n",
    "    new_itemmap = {}  # maps old item id to new sequential id\n",
    "    new_index = 1\n",
    "    # Sort keys for reproducibility.\n",
    "    for old_key in sorted(name_dict['title'].keys()):\n",
    "        new_itemmap[old_key] = new_index\n",
    "        new_title[new_index] = name_dict['title'][old_key]\n",
    "        new_description[new_index] = name_dict['description'][old_key]\n",
    "        new_index += 1\n",
    "    # Replace name_dict with re-indexed dictionaries.\n",
    "    name_dict['title'] = new_title\n",
    "    name_dict['description'] = new_description\n",
    "    new_itemnum = len(new_title)\n",
    "\n",
    "    # Update the User interactions: remap item IDs using new_itemmap.\n",
    "    for userid in User.keys():\n",
    "        for i in range(len(User[userid])):\n",
    "            old_itemid = User[userid][i][1]\n",
    "            if old_itemid in new_itemmap:\n",
    "                User[userid][i][1] = new_itemmap[old_itemid]\n",
    "\n",
    "    # Save the re-indexed meta data file.\n",
    "    output_path = os.path.join('..', '..', 'data', 'amazon', f'{fname}_text_name_dict.json.gz')\n",
    "    with open(output_path, 'wb') as tf:\n",
    "        pickle.dump(name_dict, tf)\n",
    "\n",
    "    for userid in User.keys():\n",
    "        User[userid].sort(key=lambda x: x[0])\n",
    "\n",
    "    print(\"User count:\", usernum, \"Original item count:\", itemnum, \"Re-indexed item count:\", new_itemnum)\n",
    "\n",
    "    # Write user-item interaction pairs using the new indexing.\n",
    "    txt_output = os.path.join('..', '..', 'data', 'amazon', f'{fname}.txt')\n",
    "    with open(txt_output, 'w') as f:\n",
    "        for user in User.keys():\n",
    "            for i in User[user]:\n",
    "                f.write('%d %d\\n' % (user, i[1]))\n"
   ],
   "id": "bf94b7760e4266ae"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
