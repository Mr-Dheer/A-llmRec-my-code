{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-27T13:02:53.052342Z",
     "start_time": "2025-03-27T13:02:52.899581Z"
    }
   },
   "source": "import pandas as pd",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T13:02:57.257355Z",
     "start_time": "2025-03-27T13:02:54.342189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "original_Lux = pd.read_json('Luxury_Beauty.json', lines=True)\n",
    "original_meta = pd.read_json('meta_Luxury_Beauty.json', lines=True)\n",
    "prime = pd.read_json('meta_Prime_Pantry.json', lines=True)\n",
    "\n",
    "df = original_Lux.copy()\n",
    "meta = original_meta[['title', 'description', 'asin']].copy()\n"
   ],
   "id": "722f240e2abccfd1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T10:46:24.012784Z",
     "start_time": "2025-03-27T10:46:24.009366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_set_meta = meta.sample(n=2500, random_state=42)\n",
    "test_set_meta = test_set_meta.reset_index(drop=True)"
   ],
   "id": "ee7a6e77e88b868e",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T10:46:24.058060Z",
     "start_time": "2025-03-27T10:46:24.054206Z"
    }
   },
   "cell_type": "code",
   "source": "test_set_meta.info()",
   "id": "2cb4b18e85cbdd5e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2500 entries, 0 to 2499\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   title        2500 non-null   object\n",
      " 1   description  2500 non-null   object\n",
      " 2   asin         2500 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 58.7+ KB\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T10:46:24.188373Z",
     "start_time": "2025-03-27T10:46:24.101965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_set_lux = df.sample(n=114927, random_state=42)\n",
    "test_set_lux = test_set_lux.reset_index(drop=True)"
   ],
   "id": "62aff61c10ffd4bd",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T10:46:24.255263Z",
     "start_time": "2025-03-27T10:46:24.200396Z"
    }
   },
   "cell_type": "code",
   "source": "test_set_lux.info()",
   "id": "f060a84df953459e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114927 entries, 0 to 114926\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   overall         114927 non-null  int64 \n",
      " 1   vote            20690 non-null   object\n",
      " 2   verified        114927 non-null  bool  \n",
      " 3   reviewTime      114927 non-null  object\n",
      " 4   reviewerID      114927 non-null  object\n",
      " 5   asin            114927 non-null  object\n",
      " 6   reviewerName    114921 non-null  object\n",
      " 7   reviewText      114846 non-null  object\n",
      " 8   summary         114891 non-null  object\n",
      " 9   unixReviewTime  114927 non-null  int64 \n",
      " 10  style           50267 non-null   object\n",
      " 11  image           1491 non-null    object\n",
      "dtypes: bool(1), int64(2), object(9)\n",
      "memory usage: 9.8+ MB\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T10:46:24.642695Z",
     "start_time": "2025-03-27T10:46:24.266990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_set_lux.to_json('test_Luxury_Beauty.json',orient='records', lines=True)\n",
    "\n",
    "# original_meta = test_set_meta"
   ],
   "id": "a275d64cea0eba57",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T10:46:24.664787Z",
     "start_time": "2025-03-27T10:46:24.654944Z"
    }
   },
   "cell_type": "code",
   "source": "test_set_meta.to_json('test_meta_Luxury_Beauty.json',orient='records', lines=True)",
   "id": "cfa636f211d8cf99",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T10:46:27.279242Z",
     "start_time": "2025-03-27T10:46:24.708203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "shit = pd.read_json('Luxury_Beauty.json', lines=True)"
   ],
   "id": "55f4bcaa9da541",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T10:46:27.488796Z",
     "start_time": "2025-03-27T10:46:27.283368Z"
    }
   },
   "cell_type": "code",
   "source": "shit.info()",
   "id": "a11ae14b4bfbf043",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 574628 entries, 0 to 574627\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   overall         574628 non-null  int64 \n",
      " 1   vote            103689 non-null  object\n",
      " 2   verified        574628 non-null  bool  \n",
      " 3   reviewTime      574628 non-null  object\n",
      " 4   reviewerID      574628 non-null  object\n",
      " 5   asin            574628 non-null  object\n",
      " 6   reviewerName    574597 non-null  object\n",
      " 7   reviewText      574228 non-null  object\n",
      " 8   summary         574445 non-null  object\n",
      " 9   unixReviewTime  574628 non-null  int64 \n",
      " 10  style           251013 non-null  object\n",
      " 11  image           7418 non-null    object\n",
      "dtypes: bool(1), int64(2), object(9)\n",
      "memory usage: 48.8+ MB\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T10:46:28.142991Z",
     "start_time": "2025-03-27T10:46:27.527615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chooth = pd.read_json('test_Luxury_Beauty.json', lines=True)\n",
    "maadar = pd.read_json('test_meta_Luxury_Beauty.json', lines=True)\n"
   ],
   "id": "500313d523d5392e",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T10:46:28.201439Z",
     "start_time": "2025-03-27T10:46:28.155357Z"
    }
   },
   "cell_type": "code",
   "source": "chooth.info()",
   "id": "c1b99a036e0b0551",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114927 entries, 0 to 114926\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   overall         114927 non-null  int64 \n",
      " 1   vote            20690 non-null   object\n",
      " 2   verified        114927 non-null  bool  \n",
      " 3   reviewTime      114927 non-null  object\n",
      " 4   reviewerID      114927 non-null  object\n",
      " 5   asin            114927 non-null  object\n",
      " 6   reviewerName    114921 non-null  object\n",
      " 7   reviewText      114846 non-null  object\n",
      " 8   summary         114891 non-null  object\n",
      " 9   unixReviewTime  114927 non-null  int64 \n",
      " 10  style           50267 non-null   object\n",
      " 11  image           1491 non-null    object\n",
      "dtypes: bool(1), int64(2), object(9)\n",
      "memory usage: 9.8+ MB\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T10:46:28.216281Z",
     "start_time": "2025-03-27T10:46:28.213226Z"
    }
   },
   "cell_type": "code",
   "source": "maadar.info()",
   "id": "b61357b1aedb9cf6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2500 entries, 0 to 2499\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   title        2500 non-null   object\n",
      " 1   description  2500 non-null   object\n",
      " 2   asin         2500 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 58.7+ KB\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T18:48:06.576678Z",
     "start_time": "2025-03-27T18:48:06.567340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "test = pd.read_json('test_meta_Luxury_Beauty.json', lines=True)\n",
    "with open('Luxury_Beauty_text_name_dict.json', 'rb') as f:\n",
    "    name_dict = pickle.load(f)\n",
    "df = pd.DataFrame(name_dict)"
   ],
   "id": "2e14ba683b18530d",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T18:48:25.427024Z",
     "start_time": "2025-03-27T18:48:25.422749Z"
    }
   },
   "cell_type": "code",
   "source": "test.info()",
   "id": "bac83ddaa1ca4bc6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2500 entries, 0 to 2499\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   title        2500 non-null   object\n",
      " 1   description  2500 non-null   object\n",
      " 2   asin         2500 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 58.7+ KB\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T18:48:37.083027Z",
     "start_time": "2025-03-27T18:48:37.079348Z"
    }
   },
   "cell_type": "code",
   "source": "df.info()\n",
   "id": "dc772233f77e6547",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 427 entries, 1 to 2005\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   title        427 non-null    object\n",
      " 1   description  427 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 10.0+ KB\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T13:06:55.674179Z",
     "start_time": "2025-04-07T13:06:55.664727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import os.path\n",
    "import gzip\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in tqdm(g):\n",
    "        yield json.loads(l)\n",
    "\n",
    "def preprocess(fname):\n",
    "    countU = defaultdict(lambda: 0) #counting how many reviews each user made ( reviewerID)\n",
    "    countP = defaultdict(lambda: 0) # counting how many reviews each product (asin) received.\n",
    "    line = 0\n",
    "\n",
    "    file_path = f'{fname}.json.gz' # data over here\n",
    "\n",
    "    # counting interactions for each user and item\n",
    "    for l in parse(file_path):\n",
    "        line += 1\n",
    "        asin = l['asin']\n",
    "        rev = l['reviewerID']\n",
    "        time = l['unixReviewTime']\n",
    "        countU[rev] += 1\n",
    "        countP[asin] += 1\n",
    "\n",
    "    usermap = dict()\n",
    "    usernum = 0\n",
    "    itemmap = dict()\n",
    "    itemnum = 0\n",
    "    User = dict()\n",
    "    review_dict = {}\n",
    "    name_dict = {'title':{}, 'description':{}}\n",
    "\n",
    "    f = open(f'meta_{fname}.json', 'r')\n",
    "    json_data = f.readlines()\n",
    "    f.close()\n",
    "    data_list = [json.loads(line[:-1]) for line in json_data]\n",
    "    meta_dict = {}\n",
    "    for l in data_list:\n",
    "        meta_dict[l['asin']] = l\n",
    "\n",
    "    for l in parse(file_path):\n",
    "        line += 1\n",
    "        asin = l['asin']\n",
    "        rev = l['reviewerID']\n",
    "        time = l['unixReviewTime']\n",
    "\n",
    "        # Added Magazine over here\n",
    "        threshold = 1\n",
    "        if ('Beauty' in fname) or ('Toys' in fname) or ('Magazine_Subscriptions' in fname):\n",
    "            # Changed threshold to 3 from 4  since the data is small of magazine\n",
    "            threshold = 3\n",
    "\n",
    "        if countU[rev] < threshold or countP[asin] < threshold:\n",
    "            continue\n",
    "\n",
    "        if rev in usermap:\n",
    "            userid = usermap[rev]\n",
    "        else:\n",
    "            usernum += 1\n",
    "            userid = usernum\n",
    "            usermap[rev] = userid\n",
    "            User[userid] = []\n",
    "\n",
    "        if asin in itemmap:\n",
    "            itemid = itemmap[asin]\n",
    "        else:\n",
    "            itemnum += 1\n",
    "            itemid = itemnum\n",
    "            itemmap[asin] = itemid\n",
    "        User[userid].append([time, itemid])\n",
    "\n",
    "\n",
    "        if itemmap[asin] in review_dict:\n",
    "            try:\n",
    "                review_dict[itemmap[asin]]['review'][usermap[rev]] = l['reviewText']\n",
    "            except:\n",
    "                a = 0\n",
    "            try:\n",
    "                review_dict[itemmap[asin]]['summary'][usermap[rev]] = l['summary']\n",
    "            except:\n",
    "                a = 0\n",
    "        else:\n",
    "            review_dict[itemmap[asin]] = {'review': {}, 'summary':{}}\n",
    "            try:\n",
    "                review_dict[itemmap[asin]]['review'][usermap[rev]] = l['reviewText']\n",
    "            except:\n",
    "                a = 0\n",
    "            try:\n",
    "                review_dict[itemmap[asin]]['summary'][usermap[rev]] = l['summary']\n",
    "            except:\n",
    "                a = 0\n",
    "        try:\n",
    "            if len(meta_dict[asin]['description']) ==0:\n",
    "                name_dict['description'][itemmap[asin]] = 'Empty description'\n",
    "            else:\n",
    "                name_dict['description'][itemmap[asin]] = meta_dict[asin]['description'][0]\n",
    "            name_dict['title'][itemmap[asin]] = meta_dict[asin]['title']\n",
    "        except:\n",
    "            a =0\n",
    "\n",
    "    with open(f'{fname}_draft_69.json', 'wb') as tf:\n",
    "        pickle.dump(name_dict, tf)\n",
    "\n",
    "    for userid in User.keys():\n",
    "        User[userid].sort(key=lambda x: x[0])\n",
    "\n",
    "    print(usernum, itemnum)\n",
    "\n",
    "    f = open(f'{fname}.txt', 'w') # data over here\n",
    "    for user in User.keys():\n",
    "        for i in User[user]:\n",
    "            f.write('%d %d\\n' % (user, i[1]))\n",
    "    f.close()"
   ],
   "id": "e19e6c7d3cf12824",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T13:06:59.410122Z",
     "start_time": "2025-04-07T13:06:58.273953Z"
    }
   },
   "cell_type": "code",
   "source": "preprocess('Luxury_Beauty')",
   "id": "d921719a1aa021b7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "114927it [00:00, 233948.07it/s]\n",
      "114927it [00:00, 241837.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1514 2008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T13:07:30.286535Z",
     "start_time": "2025-04-07T13:07:30.133265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open('Luxury_Beauty_draft_69.json', 'rb') as f:\n",
    "    temp = pickle.load(f)\n",
    "df2 = pd.DataFrame(temp)"
   ],
   "id": "aef380c1e5c3e01",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T13:07:45.593937Z",
     "start_time": "2025-04-07T13:07:45.589822Z"
    }
   },
   "cell_type": "code",
   "source": "df2.info()",
   "id": "1a150b9b70948650",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2007 entries, 1 to 2008\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   title        2007 non-null   object\n",
      " 1   description  2007 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 47.0+ KB\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T13:09:41.924778Z",
     "start_time": "2025-04-07T13:09:41.918268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import os.path\n",
    "import gzip\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in tqdm(g):\n",
    "        yield json.loads(l)\n",
    "\n",
    "\n",
    "def preprocess(fname):\n",
    "    countU = defaultdict(lambda: 0)\n",
    "    countP = defaultdict(lambda: 0)\n",
    "    line = 0\n",
    "\n",
    "    file_path = f'{fname}.json.gz'  # review data file\n",
    "\n",
    "    # Counting interactions for each user and item\n",
    "    for l in parse(file_path):\n",
    "        line += 1\n",
    "        asin = l['asin']\n",
    "        rev = l['reviewerID']\n",
    "        time = l['unixReviewTime']\n",
    "        countU[rev] += 1\n",
    "        countP[asin] += 1\n",
    "\n",
    "    usermap = dict()\n",
    "    usernum = 0\n",
    "    itemmap = dict()  # maps ASIN to an initial (possibly non-sequential) ID\n",
    "    itemnum = 0\n",
    "    User = dict()\n",
    "    review_dict = {}\n",
    "    name_dict = {'title': {}, 'description': {}}\n",
    "\n",
    "    # Load raw meta data\n",
    "    with open(f'meta_{fname}.json', 'r') as f:\n",
    "        json_data = f.readlines()\n",
    "    data_list = [json.loads(line.strip()) for line in json_data]\n",
    "    meta_dict = {}\n",
    "    for l in data_list:\n",
    "        meta_dict[l['asin']] = l\n",
    "\n",
    "    # Process the review data\n",
    "    for l in parse(file_path):\n",
    "        line += 1\n",
    "        asin = l['asin']\n",
    "        rev = l['reviewerID']\n",
    "        time = l['unixReviewTime']\n",
    "\n",
    "        # Set threshold for filtering interactions\n",
    "        threshold = 5\n",
    "        if ('Beauty' in fname) or ('Toys' in fname) or ('Magazine_Subscriptions' in fname):\n",
    "            threshold = 3\n",
    "\n",
    "        if countU[rev] < threshold or countP[asin] < threshold:\n",
    "            continue\n",
    "\n",
    "        # Map reviewer to a new integer ID\n",
    "        if rev in usermap:\n",
    "            userid = usermap[rev]\n",
    "        else:\n",
    "            usernum += 1\n",
    "            userid = usernum\n",
    "            usermap[rev] = userid\n",
    "            User[userid] = []\n",
    "\n",
    "        # Map product ASIN to an initial item ID\n",
    "        if asin in itemmap:\n",
    "            itemid = itemmap[asin]\n",
    "        else:\n",
    "            itemnum += 1\n",
    "            itemid = itemnum\n",
    "            itemmap[asin] = itemid\n",
    "        User[userid].append([time, itemid])\n",
    "\n",
    "        # Build review_dict (optional) and name_dict with meta data\n",
    "        if itemmap[asin] in review_dict:\n",
    "            try:\n",
    "                review_dict[itemmap[asin]]['review'][usermap[rev]] = l['reviewText']\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            try:\n",
    "                review_dict[itemmap[asin]]['summary'][usermap[rev]] = l['summary']\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        else:\n",
    "            review_dict[itemmap[asin]] = {'review': {}, 'summary': {}}\n",
    "            try:\n",
    "                review_dict[itemmap[asin]]['review'][usermap[rev]] = l['reviewText']\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            try:\n",
    "                review_dict[itemmap[asin]]['summary'][usermap[rev]] = l['summary']\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        try:\n",
    "            if len(meta_dict[asin]['description']) == 0:\n",
    "                name_dict['description'][itemmap[asin]] = 'Empty description'\n",
    "            else:\n",
    "                name_dict['description'][itemmap[asin]] = meta_dict[asin]['description'][0]\n",
    "            name_dict['title'][itemmap[asin]] = meta_dict[asin]['title']\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    # --- Re-indexing step ---\n",
    "    # Create new dictionaries with sequential keys and a mapping from old to new IDs.\n",
    "    new_title = {}\n",
    "    new_description = {}\n",
    "    new_itemmap = {}  # maps old item id to new sequential id\n",
    "    new_index = 1\n",
    "    # Sort keys for reproducibility; alternatively, you could iterate in any order.\n",
    "    for old_key in sorted(name_dict['title'].keys()):\n",
    "        new_itemmap[old_key] = new_index\n",
    "        new_title[new_index] = name_dict['title'][old_key]\n",
    "        new_description[new_index] = name_dict['description'][old_key]\n",
    "        new_index += 1\n",
    "    # Replace name_dict with re-indexed dictionaries\n",
    "    name_dict['title'] = new_title\n",
    "    name_dict['description'] = new_description\n",
    "    # Update the total number of items to reflect the new indexing\n",
    "    new_itemnum = len(new_title)\n",
    "\n",
    "    # Update the User interactions: remap item IDs using new_itemmap.\n",
    "    for userid in User.keys():\n",
    "        for i in range(len(User[userid])):\n",
    "            old_itemid = User[userid][i][1]\n",
    "            if old_itemid in new_itemmap:\n",
    "                User[userid][i][1] = new_itemmap[old_itemid]\n",
    "\n",
    "    # Save the re-indexed meta data file\n",
    "    with open(f'{fname}spidey.json.gz', 'wb') as tf:\n",
    "        pickle.dump(name_dict, tf)\n",
    "\n",
    "    for userid in User.keys():\n",
    "        User[userid].sort(key=lambda x: x[0])\n",
    "\n",
    "    print(\"User count:\", usernum, \"Original item count:\", itemnum, \"Re-indexed item count:\", new_itemnum)\n",
    "\n",
    "    # Write user-item interaction pairs using the new indexing\n",
    "    with open(f'{fname}.txt', 'w') as f:\n",
    "        for user in User.keys():\n",
    "            for i in User[user]:\n",
    "                f.write('%d %d\\n' % (user, i[1]))\n"
   ],
   "id": "5c6e0a241ee2e253",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T13:10:00.272535Z",
     "start_time": "2025-04-07T13:09:59.152316Z"
    }
   },
   "cell_type": "code",
   "source": "preprocess('Luxury_Beauty')",
   "id": "b4063cfddc0642c0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "114927it [00:00, 234837.07it/s]\n",
      "114927it [00:00, 242457.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User count: 1514 Original item count: 2008 Re-indexed item count: 2007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T13:18:38.054666Z",
     "start_time": "2025-04-07T13:18:38.050705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('Luxury_Beautyspidey.json.gz', 'rb') as f:\n",
    "    temp = pickle.load(f)\n",
    "df2 = pd.DataFrame(temp)\n"
   ],
   "id": "a88ab2c1d8dc9e41",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T13:18:40.529418Z",
     "start_time": "2025-04-07T13:18:40.525893Z"
    }
   },
   "cell_type": "code",
   "source": "df2.info()",
   "id": "3d1ee5a172e2ead4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2007 entries, 1 to 2007\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   title        2007 non-null   object\n",
      " 1   description  2007 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 47.0+ KB\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:24:36.970059Z",
     "start_time": "2025-04-11T13:24:36.964757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import os.path\n",
    "import gzip\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in tqdm(g):\n",
    "        yield json.loads(l)\n",
    "\n",
    "\n",
    "def preprocess(fname):\n",
    "    countU = defaultdict(lambda: 0)\n",
    "    countP = defaultdict(lambda: 0)\n",
    "    line = 0\n",
    "\n",
    "    file_path = f'{fname}.json.gz'  # review data file\n",
    "\n",
    "    # Counting interactions for each user and item\n",
    "    for l in parse(file_path):\n",
    "        line += 1\n",
    "        asin = l['asin']\n",
    "        rev = l['reviewerID']\n",
    "        time = l['unixReviewTime']\n",
    "        countU[rev] += 1\n",
    "        countP[asin] += 1\n",
    "\n",
    "    usermap = dict()\n",
    "    usernum = 0\n",
    "    itemmap = dict()  # maps ASIN to an initial (possibly non-sequential) ID\n",
    "    itemnum = 0\n",
    "    User = dict()\n",
    "    review_dict = {}\n",
    "    name_dict = {'title': {}, 'description': {}}\n",
    "\n",
    "    # Load raw meta data\n",
    "    with open(f'meta_{fname}.json', 'r') as f:\n",
    "        json_data = f.readlines()\n",
    "    data_list = [json.loads(line.strip()) for line in json_data]\n",
    "    meta_dict = {}\n",
    "    for l in data_list:\n",
    "        meta_dict[l['asin']] = l\n",
    "\n",
    "    # Process the review data\n",
    "    for l in parse(file_path):\n",
    "        line += 1\n",
    "        asin = l['asin']\n",
    "        rev = l['reviewerID']\n",
    "        time = l['unixReviewTime']\n",
    "\n",
    "        # Set threshold for filtering interactions\n",
    "        threshold = 5\n",
    "        if ('Beauty' in fname) or ('Toys' in fname) or ('Magazine_Subscriptions' in fname):\n",
    "            threshold = 3\n",
    "\n",
    "        if countU[rev] < threshold or countP[asin] < threshold:\n",
    "            continue\n",
    "\n",
    "        # Map reviewer to a new integer ID\n",
    "        if rev in usermap:\n",
    "            userid = usermap[rev]\n",
    "        else:\n",
    "            usernum += 1\n",
    "            userid = usernum\n",
    "            usermap[rev] = userid\n",
    "            User[userid] = []\n",
    "\n",
    "        # Map product ASIN to an initial item ID\n",
    "        if asin in itemmap:\n",
    "            itemid = itemmap[asin]\n",
    "        else:\n",
    "            itemnum += 1\n",
    "            itemid = itemnum\n",
    "            itemmap[asin] = itemid\n",
    "        User[userid].append([time, itemid])\n",
    "\n",
    "        # Build review_dict (optional) and name_dict with meta data\n",
    "        if itemmap[asin] in review_dict:\n",
    "            try:\n",
    "                review_dict[itemmap[asin]]['review'][usermap[rev]] = l['reviewText']\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            try:\n",
    "                review_dict[itemmap[asin]]['summary'][usermap[rev]] = l['summary']\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        else:\n",
    "            review_dict[itemmap[asin]] = {'review': {}, 'summary': {}}\n",
    "            try:\n",
    "                review_dict[itemmap[asin]]['review'][usermap[rev]] = l['reviewText']\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            try:\n",
    "                review_dict[itemmap[asin]]['summary'][usermap[rev]] = l['summary']\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        try:\n",
    "            if len(meta_dict[asin]['description']) == 0:\n",
    "                name_dict['description'][itemmap[asin]] = 'Empty description'\n",
    "            else:\n",
    "                name_dict['description'][itemmap[asin]] = meta_dict[asin]['description'][0]\n",
    "            name_dict['title'][itemmap[asin]] = meta_dict[asin]['title']\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    # --- Re-indexing step ---\n",
    "    # Create new dictionaries with sequential keys and a mapping from old to new IDs.\n",
    "    new_title = {}\n",
    "    new_description = {}\n",
    "    new_itemmap = {}  # maps old item id to new sequential id\n",
    "    new_index = 1\n",
    "    # Sort keys for reproducibility; alternatively, you could iterate in any order.\n",
    "    for old_key in sorted(name_dict['title'].keys()):\n",
    "        new_itemmap[old_key] = new_index\n",
    "        new_title[new_index] = name_dict['title'][old_key]\n",
    "        new_description[new_index] = name_dict['description'][old_key]\n",
    "        new_index += 1\n",
    "    # Replace name_dict with re-indexed dictionaries\n",
    "    name_dict['title'] = new_title\n",
    "    name_dict['description'] = new_description\n",
    "    # Update the total number of items to reflect the new indexing\n",
    "    new_itemnum = len(new_title)\n",
    "\n",
    "    # Update the User interactions: remap item IDs using new_itemmap.\n",
    "    for userid in User.keys():\n",
    "        for i in range(len(User[userid])):\n",
    "            old_itemid = User[userid][i][1]\n",
    "            if old_itemid in new_itemmap:\n",
    "                User[userid][i][1] = new_itemmap[old_itemid]\n",
    "\n",
    "    # Save the re-indexed meta data file\n",
    "    with open(f'{fname}_small_check.gz', 'wb') as tf:\n",
    "        pickle.dump(name_dict, tf)\n",
    "\n",
    "    for userid in User.keys():\n",
    "        User[userid].sort(key=lambda x: x[0])\n",
    "\n",
    "    print(\"User count:\", usernum, \"Original item count:\", itemnum, \"Re-indexed item count:\", new_itemnum)\n",
    "\n",
    "    # Write user-item interaction pairs using the new indexing\n",
    "    with open(f'{fname}.txt', 'w') as f:\n",
    "        for user in User.keys():\n",
    "            for i in User[user]:\n",
    "                f.write('%d %d\\n' % (user, i[1]))\n"
   ],
   "id": "f3b32688346bd28f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:24:38.809953Z",
     "start_time": "2025-04-11T13:24:38.788745Z"
    }
   },
   "cell_type": "code",
   "source": "preprocess('meta_daredevil')",
   "id": "9b4c00674526af59",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'meta_daredevil.json.gz'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mpreprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmeta_daredevil\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[7], line 24\u001B[0m, in \u001B[0;36mpreprocess\u001B[0;34m(fname)\u001B[0m\n\u001B[1;32m     21\u001B[0m file_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.json.gz\u001B[39m\u001B[38;5;124m'\u001B[39m  \u001B[38;5;66;03m# review data file\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# Counting interactions for each user and item\u001B[39;00m\n\u001B[0;32m---> 24\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43ml\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mparse\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile_path\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[43m    \u001B[49m\u001B[43mline\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\n\u001B[1;32m     26\u001B[0m \u001B[43m    \u001B[49m\u001B[43masin\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43ml\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43masin\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n",
      "Cell \u001B[0;32mIn[7], line 11\u001B[0m, in \u001B[0;36mparse\u001B[0;34m(path)\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mparse\u001B[39m(path):\n\u001B[0;32m---> 11\u001B[0m     g \u001B[38;5;241m=\u001B[39m \u001B[43mgzip\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m tqdm(g):\n\u001B[1;32m     13\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m json\u001B[38;5;241m.\u001B[39mloads(l)\n",
      "File \u001B[0;32m~/Dev/anaconda3/envs/ALLM-Rec/lib/python3.12/gzip.py:61\u001B[0m, in \u001B[0;36mopen\u001B[0;34m(filename, mode, compresslevel, encoding, errors, newline)\u001B[0m\n\u001B[1;32m     59\u001B[0m gz_mode \u001B[38;5;241m=\u001B[39m mode\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mt\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(filename, (\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mbytes\u001B[39m, os\u001B[38;5;241m.\u001B[39mPathLike)):\n\u001B[0;32m---> 61\u001B[0m     binary_file \u001B[38;5;241m=\u001B[39m \u001B[43mGzipFile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgz_mode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcompresslevel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(filename, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mread\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(filename, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwrite\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     63\u001B[0m     binary_file \u001B[38;5;241m=\u001B[39m GzipFile(\u001B[38;5;28;01mNone\u001B[39;00m, gz_mode, compresslevel, filename)\n",
      "File \u001B[0;32m~/Dev/anaconda3/envs/ALLM-Rec/lib/python3.12/gzip.py:192\u001B[0m, in \u001B[0;36mGzipFile.__init__\u001B[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001B[0m\n\u001B[1;32m    190\u001B[0m     mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    191\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fileobj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 192\u001B[0m     fileobj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmyfileobj \u001B[38;5;241m=\u001B[39m \u001B[43mbuiltins\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    193\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m filename \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    194\u001B[0m     filename \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(fileobj, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'meta_daredevil.json.gz'"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
